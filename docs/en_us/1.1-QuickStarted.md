# Getting Started

1. Download the MaaFramework Release
2. Prepare Resource Files
3. Use a Generic CLI or Write Integration Code

## Download the MaaFramework Release

Download and extract the MaaFramework release that matches your platform: [Releases](https://github.com/MaaAssistantArknights/MaaFramework/releases)

## Prepare Resource Files

You need to prepare some resource files with the typical file structure as follows:

```tree
my_resource
├── image
│   ├── my_image_1.png
│   └── my_image_2.png
├── model
│   └── ocr
│       ├── det.onnx
│       ├── keys.txt
│       └── rec.onnx
└── pipeline
    ├── my_pipeline_1.json
    └── my_pipeline_2.json
```

You can modify the names of files and folders starting with "my_", but the others have fixed file names and should not be changed. Here's a breakdown:

### Pipeline JSON Files

The files in `my_resource/pipeline` contain the main script execution logic and recursively read all JSON format files in the directory.

You can refer to the [Task Pipeline Protocol](3.1-PipelineProtocol.md) for writing these files. You can find a simple [demo](https://github.com/MaaAssistantArknights/MaaFramework/blob/main/sample/resource/pipeline/sample.json) for reference.

Tools:

- [JSON Schema](https://github.com/MaaAssistantArknights/MaaFramework/blob/main/tools/pipeline.schema.json)
- [VSCode Extension](https://marketplace.visualstudio.com/items?itemName=nekosu.maa-support)

### Image Files

The files in `my_resource/image` are primarily used for template matching images, feature detection images, and other images required by the pipeline. They are read based on the `template` and other fields specified in the pipeline.

Tools:

- [Image Cropping and ROI Extraction Tool](https://github.com/MaaAssistantArknights/MaaFramework/tree/main/tools/ImageCropper)

### Text Recognition Model Files

The files in `my_resource/model/ocr` are ONNX models obtained from [PaddleOCR](https://github.com/PaddlePaddle/PaddleOCR) after conversion.

You can use our pre-converted files: [MaaCommonAssets](https://github.com/MaaAssistantArknights/MaaCommonAssets/tree/main/OCR). Choose the language you need and store them according to the directory structure mentioned above in [Prepare Resource Files](#prepare-resource-files).

If needed, you can also fine-tune the official pre-trained models of PaddleOCR yourself (please refer to the official PaddleOCR documentation) and convert them to ONNX files for use. You can find conversion commands [here](https://github.com/MaaAssistantArknights/MaaCommonAssets/tree/main/OCR#command).

## Run

You can integrate MaaFramework using MaaPiCli (Generic CLI) or by writing integration code yourself.

### Using MaaPiCli

Use MaaPiCli in the `bin` folder of the Release package, and write `interface.json` and place it in the same directory to use it.

The Cli has completed basic function development, and more functions are being continuously improved! Detailed documentation needs to be further improved. Currently, you can refer to sample to write it.

Examples:

- [Sample](https://github.com/MaaAssistantArknights/MaaFramework/blob/main/sample/interface.json)
- [M9A](https://github.com/MaaAssistantArknights/M9A/tree/main/assets/interface.json)

### Writing Integration Code Yourself

Please refer to the [Integration Documentation](2.1-Integration.md).

Examples:

- [M9A](https://github.com/MaaAssistantArknights/M9A) - Integration practice based on C++ & cmake
- [MBA](https://github.com/MaaAssistantArknights/MBA) - Integration practice based on C# .NET
